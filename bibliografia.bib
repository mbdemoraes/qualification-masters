@article{Goncalves2014,
abstract = {In data stream environments, drift detection methods are used to identify when the context has changed. This paper evaluates eight different concept drift detectors (ddm, eddm, pht, stepd, dof, adwin, Paired Learners, and ecdd) and performs tests using artificial datasets affected by abrupt and gradual concept drifts, with several rates of drift, with and without noise and irrelevant attributes, and also using real-world datasets. In addition, a 2k factorial design was used to indicate the parameters that most influence performance which is a novelty in the area. Also, a variation of the Friedman non-parametric statistical test was used to identify the best methods. Experiments compared accuracy, evaluation time, as well as false alarm and miss detection rates. Additionally, we used the Mahalanobis distance to measure how similar the methods are when compared to the best possible detection output. This work can, to some extent, also be seen as a research survey of existing drift detection methods.},
annote = {Artigo com um estudo comparativo entre detectores de concept drift, que apresenta v{\'{a}}rios tipos existentes e seus desempenhos diante de alguns crit{\'{e}}rios. Apresenta datasets importantes e previamente utilizados na {\'{a}}rea de concept drift.},
author = {{GON\c{C}ALVES JR.}, Paulo M. and {de Carvalho Santos}, Silas G.T. and Barros, Roberto S.M. and Vieira, Davi C.L.},
doi = {10.1016/j.eswa.2014.07.019},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gon{\c{c}}alves et al. - 2014 - A comparative study on concept drift detectors(2).pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
number = {18},
pages = {8144--8156},
title = {{A comparative study on concept drift detectors}},
volume = {41},
year = {2014}
}
@article{Carmona-Cejudo2013,
abstract = {Email foldering is a challenging problem mainly due to its high dimensionality and dynamic nature. This work presents ABC-DynF, an adaptive learning framework with dynamic feature space that we use to compare several incremental and adaptive strategies to cope with these two difficulties. Several studies have been carried out using datasets from the ENRON email corpus and different configuration settings of the framework. The main aim is to study how feature ranking methods, concept drift monitoring, adaptive strategies and the implementation of a dynamic feature space can affect the performance of Bayesian email classification systems.},
annote = {Artigo que apresenta um estudo de caso ao aplicar t{\'{e}}cnicas de sele{\c{c}}{\~{a}}o de atributos como etapa de pr{\'{e}}-processamento para otimiza{\c{c}}{\~{a}}o do processo de classifica{\c{c}}{\~{a}}o no armazenamento autom{\'{a}}tico de e-mails (email foldering).},
author = {Carmona-Cejudo, Jos{\'{e}} M. and Castillo, Gladys and Baena-Garc{\'{i}}a, Manuel and Morales-Bueno, Rafael},
doi = {10.1016/j.knosys.2013.03.006},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Carmona-Cejudo et al. - 2013 - A comparative study on feature selection and adaptive strategies for email foldering using the ABC-Dyn(2).pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
pages = {81--94},
title = {{A comparative study on feature selection and adaptive strategies for email foldering using the ABC-DynF framework}},
volume = {46},
year = {2013}
}
@inproceedings{Wankhade2013,
annote = {Artigo que apresenta um algoritmo de sele{\c{c}}{\~{a}}o de atributos h{\'{i}}brido, baseado em Informa{\c{c}}{\~{a}}o Mut{\'{u}}a e Algoritmos Gen{\'{e}}ticos, para otimiza{\c{c}}{\~{a}}o do processo de classifica{\c{c}}{\~{a}}o de dados em fluxo.},
author = {Wankhade, Kapil and Rane, Dhiraj and Thool, Ravindra},
booktitle = {2013 International Conference on Advances in Computing, Communications and Informatics (ICACCI)},
doi = {10.1109/ICACCI.2013.6637462},
isbn = {978-1-4673-6217-7},
month = {aug},
pages = {1843--1848},
publisher = {IEEE},
address = {Mysore, India},
title = {{A new feature selection algorithm for stream Data Classification}},
year = {2013}
}
@article{Siddiqa2016,
abstract = {The rapid growth of emerging applications and the evolution of cloud computing technologies have significantly enhanced the capability to generate vast amounts of data. Thus, it has become a great challenge in this big data era to manage such voluminous amount of data. The recent advancements in big data techniques and technologies have enabled many enterprises to handle big data efficiently. However, these advances in techniques and technologies have not yet been studied in detail and a comprehensive survey of this domain is still lacking. With focus on big data management, this survey aims to investigate feasible techniques of managing big data by emphasizing on storage, pre-processing, processing and security. Moreover, the critical aspects of these techniques are analyzed by devising a taxonomy in order to identify the problems and proposals made to alleviate these problems. Furthermore, big data management techniques are also summarized. Finally, several future research directions are presented.},
annote = {Artigo que apresenta o estado da arte e a taxonomia dos principais conceitos que envolvem Big Data.},
author = {Siddiqa, Aisha and Hashem, Ibrahim Abaker Targio and Yaqoob, Ibrar and Marjani, Mohsen and Shamshirband, Shahabuddin and Gani, Abdullah and Nasaruddin, Fariza},
doi = {10.1016/j.jnca.2016.04.008},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Siddiqa et al. - 2016 - A survey of big data management Taxonomy and state-of-the-art(2).pdf:pdf},
issn = {10848045},
journal = {Journal of Network and Computer Applications},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
pages = {151--166},
title = {{A survey of big data management: Taxonomy and state-of-the-art}},
volume = {71},
year = {2016}
}
@article{Gama2014,
abstract = {Concept drift refers to a non stationary learning problem over time. The training and the application data often mismatch in real life problems. In this report we present a context of concept drift problem 1. We focus on the issues relevant to adaptive training set formation. We present the framework and terminology, and formulate a global picture of concept drift learners design. We start with formalizing the framework for the concept drifting data in Section 1. In Section 2 we discuss the adaptivity mechanisms of the concept drift learners. In Section 3 we overview the principle mechanisms of concept drift learners. In this chapter we give a general picture of the available algorithms and categorize them based on their properties. Section 5 discusses the related research fields and Section 5 groups and presents major concept drift applications. This report is intended to give a bird's view of concept drift research field, provide a context of the research and position it within broad spectrum of research fields and applications.},
annote = {Artigo escohido por ser uma das refer{\^{e}}ncias mais utilizadas quanto {\`{a}} conceitua{\c{c}}{\~{a}}o do que {\'{e}} concept drift, quais tipos existem e como detect{\'{a}}-los. T{\^{e}}m como autor principal um dos nomes mais conceituados da {\'{a}}rea, Jo{\~{a}}o Gama.},
archivePrefix = {arXiv},
arxivId = {1010.4784},
author = {Gama, Jo{\~{a}}o and {\v{Z}}liobaitė, Indrė and Bifet, Albert and Pechenizkiy, Mykola and Bouchachia, Abdelhamid},
doi = {10.1145/2523813},
eprint = {1010.4784},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gama et al. - 2014 - A survey on concept drift adaptation(2).pdf:pdf},
isbn = {1011158908},
issn = {03600300},
journal = {ACM Computing Surveys},
mendeley-groups = {Adsense/ACM Potenciais (Titulo),An{\'{a}}lise completa},
month = {mar},
number = {4},
pages = {1--37},
pmid = {21824845},
title = {{A survey on concept drift adaptation}},
volume = {46},
year = {2014}
}
@article{Ramirez-Gallego2017,
abstract = {Data preprocessing and reduction have become essential techniques in current knowledge discovery scenarios, dominated by increasingly large datasets. These methods aim at reducing the complexity inherent to real-world datasets, so that they can be easily processed by current data mining solutions. Advantages of such approaches include, among others, a faster and more precise learning process, and more understandable structure of raw data. However, in the context of data preprocessing techniques for data streams have a long road ahead of them, despite online learning is growing in importance thanks to the development of Internet and technologies for massive data collection. Throughout this survey, we summarize, categorize and analyze those contributions on data preprocessing that cope with streaming data. This work also takes into account the existing relationships between the different families of methods (feature and instance selection, and discretization). To enrich our study, we conduct thorough experiments using the most relevant contributions and present an analysis of their predictive performance, reduction rates, computational time, and memory usage. Finally, we offer general advices about existing data stream preprocessing algorithms, as well as discuss emerging future challenges to be faced in the domain of data stream preprocessing.},
annote = {Artigo escolhido por trazer o estado da arte das t{\'{e}}cnicas de pr{\'{e}}-processamento em fluxos de dados online.},
author = {Ram{\'{i}}rez-Gallego, Sergio and Krawczyk, Bartosz and Garc{\'{i}}a, Salvador and Wo{\'{z}}niak, Micha{\l} and Herrera, Francisco},
doi = {10.1016/j.neucom.2017.01.078},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ram{\'{i}}rez-Gallego et al. - 2017 - A survey on data preprocessing for data stream mining Current status and future directions(4).pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
pages = {39--57},
title = {{A survey on data preprocessing for data stream mining: Current status and future directions}},
volume = {239},
year = {2017}
}
@article{Barddal2017,
annote = {Artigo selecionado por descrever defini{\c{c}}{\~{o}}es e o estado da arte dos algoritmos e t{\'{e}}cnicas de adapta{\c{c}}{\~{o}}es {\`{a}}s mudan{\c{c}}as nos atributos em fluxos de dados online.},
author = {Barddal, Jean Paul and Gomes, Heitor Murilo and Enembreck, Fabr{\'{i}}cio and Pfahringer, Bernhard},
doi = {10.1016/j.jss.2016.07.005},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Barddal et al. - 2017 - A survey on feature drift adaptation Definition, benchmark, challenges and future directions(2).pdf:pdf},
issn = {01641212},
journal = {Journal of Systems and Software},
mendeley-groups = {Web of Science Potenciais (Titulo),An{\'{a}}lise completa},
month = {may},
pages = {278--294},
title = {{A survey on feature drift adaptation: Definition, benchmark, challenges and future directions}},
volume = {127},
year = {2017}
}
@article{Bolon-Canedo2016,
abstract = {With the advent of Big Data, data is being collected at an unprecedented fast pace, and it needs to be processed in a short time. To deal with data streams that flow continuously, classical batch learning algorithms cannot be applied and it is necessary to employ online approaches. Online learning consists of continuously revising and refining a model by incorporating new data as they arrive, and it allows important problems such as concept drift or management of extremely high-dimensional datasets to be solved. In this paper, we present a unified pipeline for online learning which covers online discretization, feature selection and classification. Three classical methods—the k-means discretizer, the $\chi$2 filter and a one-layer artificial neural network—have been reimplemented to be able to tackle online data, showing promising results on both synthetic and real datasets.},
annote = {Artigo selecionado por trazer um algoritmo de sele{\c{c}}{\~{a}}o de atributos que atua juntamente com um classificador de fluxos de dados online.},
author = {Bolon-Canedo, Veronica and Fern{\'{a}}ndez-Francos, Diego and Peteiro-Barral, Diego and Alonso-Betanzos, Amparo and Guijarro-Berdi{\~{n}}as, Bertha and S{\'{a}}nchez-Maro{\~{n}}o, Noelia},
doi = {10.1016/j.eswa.2016.02.035},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bolon-Canedo et al. - 2016 - A unified pipeline for online feature selection and classification(2).pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
pages = {532--545},
title = {{A unified pipeline for online feature selection and classification}},
volume = {55},
year = {2016}
}
@article{Singh2015,
abstract = {Anomaly based Intrusion Detection Systems (IDS) learn normal and anomalous behavior by analyzing network traffic in various benchmark datasets. Common challenges for IDSs are large amounts of data to process, low detection rates and high rates of false alarms. In this paper, a technique based on the Online Sequential Extreme Learning Machine (OS-ELM) is presented for intrusion detection. The proposed technique uses alpha profiling to reduce the time complexity while irrelevant features are discarded using an ensemble of Filtered, Correlation and Consistency based feature selection techniques. Instead of sampling, beta profiling is used to reduce the size of the training dataset. For performance evaluation of proposed technique the standard NSL-KDD 2009 (Network Security Laboratory-Knowledge Discovery and Data Mining) dataset is used. In this paper time and space complexity of the proposed technique is also discussed. The experimental results yielded an accuracy of 98.66{\%} with a false positive rate of 1.74{\%} and a detection time of 2.43 s for binary class NSL-KDD dataset. The proposed IDS achieve 97.67{\%} of accuracy with 1.74{\%} of false positive rate in 2.65 s of detection time for multi-class NSL-KDD dataset. The Kyoto University benchmark dataset is also used to test the proposed IDS. Accuracy of 96.37{\%} with false positive rate of 5.76{\%} is yielded by the proposed technique. The proposed technique outperforms other published techniques in terms of accuracy, false positive rate and detection time. Based on the experimental results achieved, we conclude that the proposed technique is an efficient method for network intrusion detection.},
annote = {Artigo que apresenta uma t{\'{e}}cnica de detec{\c{c}}{\~{a}}o de intrusos em uma rede online {\`{a}} partir de diversos m{\'{e}}todos, incluindo a utiliza{\c{c}}{\~{a}}o de sele{\c{c}}{\~{a}}o de atributos nos dados recebidos. Os autores utilizam um dataset que pode ser utilizado no trabalho.},
author = {Singh, Raman and Kumar, Harish and Singla, R.K.},
doi = {10.1016/j.eswa.2015.07.015},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh, Kumar, Singla - 2015 - An intrusion detection system using network traffic profiling and online sequential extreme learning ma(2).pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
number = {22},
pages = {8609--8624},
title = {{An intrusion detection system using network traffic profiling and online sequential extreme learning machine}},
volume = {42},
year = {2015}
}
@incollection{Barddal2015,
author = {Barddal, Jean Paul and Gomes, Heitor Murilo and Enembreck, Fabr{\'{i}}cio},
doi = {10.1007/978-3-319-26532-2_3},
pages = {21--28},
title = {{Analyzing the Impact of Feature Drifts in Streaming Learning}},
year = {2015},
address = {Istanbul, Turkey},
booktitle   = "Neural Information Processing ",
publisher = {SpringerLink}
}

@inproceedings{Cassidy2014,
author = {Cassidy, Andrew Phelps and Deviney, Frank A.},
booktitle = {2014 IEEE International Conference on Big Data (Big Data)},
doi = {10.1109/BigData.2014.7004352},
isbn = {978-1-4799-5666-1},
month = {oct},
pages = {23--28},
address = {Washington DC, USA},
publisher = {IEEE},
title = {{Calculating feature importance in data streams with concept drift using Online Random Forest}},
year = {2014}
}

@article{Garcia-Osorio2010,
abstract = {Instance selection is becoming increasingly relevant due to the huge amount of data that is constantly being produced in many fields of research. Although current algorithms are useful for fairly large datasets, scaling problems are found when the number of instances is in the hundreds of thousands or millions. When we face huge problems, scalability becomes an issue, and most algorithms are not applicable. Thus, paradoxically, instance selection algorithms are for the most part impracticable for the same problems that would benefit most from their use. This paper presents a way of avoiding this difficulty using several rounds of instance selection on subsets of the original dataset. These rounds are combined using a voting scheme to allow good performance in terms of testing error and storage reduction, while the execution time of the process is significantly reduced. The method is particularly efficient when we use instance selection algorithms that are high in computational cost. The proposed approach shares the philosophy underlying the construction of ensembles of classifiers. In an ensemble, several weak learners are combined to form a strong classifier; in our method several weak (in the sense that they are applied to subsets of the data) instance selection algorithms are combined to produce a strong and fast instance selection method. An extensive comparison of 30 medium and large datasets from the UCI Machine Learning Repository using 3 different classifiers shows the usefulness of our method. Additionally, the method is applied to 5 huge datasets (from three hundred thousand to more than a million instances) with good results and fast execution time.},
annote = {Artigo que apresenta uma outra t{\'{e}}cnica de redu{\c{c}}{\~{a}}o de dados, Instance Selection, utilizada para reduzir inst{\^{a}}ncias ao inv{\'{e}}s de atributos. Apresenta diversos datasets interessantes que podem ser utilizados no trabalho.},
author = {Garc{\'{i}}a-Osorio, C{\'{e}}sar and de Haro-Garc{\'{i}}a, Aida and Garc{\'{i}}a-Pedrajas, Nicol{\'{a}}s},
doi = {10.1016/j.artint.2010.01.001},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Garc{\'{i}}a-Osorio, de Haro-Garc{\'{i}}a, Garc{\'{i}}a-Pedrajas - 2010 - Democratic instance selection A linear complexity instance selection algorith(3).pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
number = {5},
pages = {410--441},
title = {{Democratic instance selection: A linear complexity instance selection algorithm based on classifier ensemble concepts}},
volume = {174},
year = {2010}
}

@incollection{Turkov2016,
author = {Turkov, Pavel and Krasotkina, Olga and Mottl, Vadim and Sychugov, Alexey},
doi = {10.1007/978-3-319-41920-6_48},
booktitle = {12th International Conference on Machine Learning and Data Mining in Pattern Recognition},
publisher = {SpringerLink},
address = {New York, USA},
mendeley-groups = {Web of Science Potenciais (Titulo),An{\'{a}}lise completa},
pages = {614--629},
title = {{Feature Selection for Handling Concept Drift in the Data Stream Classification}},
year = {2016}
}
@article{Yue2008,
abstract = {As data streams are gaining prominence in a growing number of emerging applications, advanced analysis and mining of data streams is becoming increasingly important. In this paper, an immune-inspired incremental feature selection algorithm called ISFaiNET is proposed as a solution for mining data streams, immune network memory antibody set which is far less than the size of data streams is design as a sketch data set. We can get the change features to the most extent by this set. ISFaiNET have the ability of feature extraction of dynamically tracking increasing huge size information by introducing increment strategy such as window mechanism. The empirical results for our algorithm are presented and discussed which demonstrate acceptable accuracy coupled with efficiency in running time.},
annote = {Artigo que apresenta um algoritmo imuno-inspirado para sele{\c{c}}{\~{a}}o de atributos em data streams.},
author = {Yue, Xun and Mo, Hongwei and Chi, Zhong-Xian},
doi = {10.1016/j.asoc.2007.03.013},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yue, Mo, Chi - 2008 - Immune-inspired incremental feature selection technology to data streams(2).pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
number = {2},
pages = {1041--1049},
title = {{Immune-inspired incremental feature selection technology to data streams}},
volume = {8},
year = {2008}
}

@inproceedings{Wang2016,
abstract = {Data streams classification poses three major challenges, namely, infinite length, concept-drift, and featureevolution. The first two issues have been widely studied. However, most existing data stream classification techniques ignore the last one. DXMiner [17], the first model which addresses featureevolution by using the past labeled instances to select the top ranked features based on a scores computed by a formula. This semi-supervised feature selection method depends on the quality of the past classification and neglects the possible correlation among different features, thus unable to produce an optimal feature subset which deteriorates the accuracy of classification. Multi-Cluster Feature Selection (MCFS) [5] proposed for static data classification and clustering applies unsupervised feature selection to address the feature-evolution problem, but suffers from the high computational cost in feature selection. In this paper, we apply MCFS in the DXMiner framework to handle each window of data in a data stream for dynamic data stream-classification. With unsupervised feature selection, our method produces the optimal feature subset and hence improves DXMiner on the classification accuracy. We further improve the time complexity of the feature selection process in MCFS by using the locality sensitive hashing forest (LSH Forest) [4]. The empirical results indicate that our approach outperforms stateof- the-art streams classification techniques in classifying real-life data streams.},
annote = {Esse artigo apresenta um estudo de como a sele{\c{c}}{\~{a}}o de atributos otimiza o processo de de classifica{\c{c}}{\~{a}}o em data streams.},
author = {Wang, Lulu and Shen, Hong},
booktitle = {2016 17th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT)},
doi = {10.1109/PDCAT.2016.056},
isbn = {978-1-5090-5081-9},
mendeley-groups = {Web of Science Potenciais (Titulo),An{\'{a}}lise completa},
month = {dec},
pages = {221--226},
publisher = {IEEE},
title = {{Improved Data Streams Classification with Fast Unsupervised Feature Selection}},
address = {Guangzhou, China},
year = {2016}
}
@inproceedings{Stiglic2011,
annote = {Artigo selecionado por apresentar um dataset com concept drift e um m{\'{e}}todo de visualiza{\c{c}}{\~{a}}o para comprovar a exist{\^{e}}ncia de concept drift.},
author = {Stiglic, Gregor and Kokol, Peter},
booktitle = {2011 IEEE 11th International Conference on Data Mining Workshops},
doi = {10.1109/ICDMW.2011.104},
isbn = {978-1-4673-0005-6},
mendeley-groups = {IEEE Potenciais (Titulo),An{\'{a}}lise completa},
month = {dec},
pages = {609--613},
publisher = {IEEE},
address = {Vancouver, Canada},
title = {{Interpretability of Sudden Concept Drift in Medical Informatics Domain}},
year = {2011}
}
@article{Li2015,
abstract = {Few online classification algorithms based on traditional inductive ensembling, such as online bagging or boosting, focus on handling concept drifting data streams while performing well on noisy data. Motivated by this, an incremental algorithm based on Ensemble Decision Trees for Concept-drifting data streams (EDTC) is proposed in this paper. Three variants of random feature selection are introduced to implement split-tests and two thresholds specified in Hoeffding Bounds inequality are utilized to distinguish concept drifts from noisy data. Extensive studies on synthetic and real streaming databases demonstrate that our algorithm of EDTC performs very well compared to several known online algorithms based on single models and ensemble models. A conclusion is hence drawn that multiple solutions are provided for learning from concept drifting data streams under noise.},
annote = {Artigo que apresenta a aplica{\c{c}}{\~{a}}o de um ensemble de {\'{a}}rvores de decis{\~{a}}o em data streams com concept drift. Apresenta datasets que podem ser utilizados neste trabalho.},
author = {Li, Peipei and Wu, Xindong and Hu, Xuegang and Wang, Hao},
doi = {10.1016/j.neucom.2015.04.024},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2015 - Learning concept-drifting data streams with random ensemble decision trees(2).pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
pages = {68--83},
title = {{Learning concept-drifting data streams with random ensemble decision trees}},
volume = {166},
year = {2015}
}
@article{Jankowski2016,
abstract = {This paper addresses a data mining task of classifying data stream with concept drift. The proposed algorithm, named Concept-adapting Evolutionary Algorithm For Decision Tree does not require any knowledge of the environment such as numbers and rates of drifts. The novelty of the approach is combining tree learner and evolutionary algorithm, where the decision tree is learned incrementally and all information is stored in an internal structure of the trees' population. The proposed algorithm is experimentally compared with state-of-the-art stream methods on several real live and synthetic datasets. Results indicate its high performance in term of accuracy and processing time.},
annote = {Artigo que apresenta a aplica{\c{c}}{\~{a}}o de um {\'{a}}rvore de decis{\~{a}}o em data streams com concept drift. Apresenta datasets que podem ser utilizados neste trabalho.},
author = {Jankowski, Dariusz and Jackowski, Konrad and Cyganek, Bogus{\l}aw},
doi = {10.1016/j.procs.2016.05.508},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jankowski, Jackowski, Cyganek - 2016 - Learning Decision Trees from Data Streams with Concept Drift(2).pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
pages = {1682--1691},
title = {{Learning Decision Trees from Data Streams with Concept Drift}},
volume = {80},
year = {2016}
}
@article{Gomes2014,
annote = {Artigo que apresenta um m{\'{e}}todo para lidar com concept drifts recorrentes em um ambiente em que os atributos mudam com o tempo.},
author = {Gomes, Joao Bartolo and Gaber, Mohamed Medhat and Sousa, Pedro A. C. and Menasalvas, Ernestina},
doi = {10.1109/TNNLS.2013.2271915},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gomes et al. - 2014 - Mining Recurring Concepts in a Dynamic Feature Space(2).pdf:pdf},
issn = {2162-237X},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
mendeley-groups = {Web of Science Potenciais (Titulo),An{\'{a}}lise completa},
month = {jan},
number = {1},
pages = {95--110},
title = {{Mining Recurring Concepts in a Dynamic Feature Space}},
volume = {25},
year = {2014}
}

@inproceedings{Bifet2009,
address = {New York, New York, USA},
annote = {Artigo que apresenta geradores e simuladores de data streams com concept drift e algumas informa{\c{c}}{\~{o}}es pertinentes sobre esse fen{\^{o}}meno.},
author = {Bifet, Albert and Holmes, Geoff and Pfahringer, Bernhard and Kirkby, Richard and Gavald{\`{a}}, Ricard},
booktitle = {Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '09},
doi = {10.1145/1557019.1557041},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bifet et al. - 2009 - New ensemble methods for evolving data streams(2).pdf:pdf},
isbn = {9781605584959},
mendeley-groups = {Adsense/ACM Potenciais (Titulo),An{\'{a}}lise completa},
pages = {139},
publisher = {ACM Press},
title = {{New ensemble methods for evolving data streams}},
year = {2009}
}

@article{Razmjoo2017,
abstract = {Online learning is a growing branch of data mining which allows all traditional data mining techniques to be applied on a online stream of data in real time. In this paper, we present a fast and efficient online sensitivity based feature ranking method (SFR) which is updated incrementally. We take advantage of the concept of global sensitivity and rank features based on their impact on the outcome of the classification model. In the feature selection part, we use a two-stage filtering method in order to first eliminate highly correlated and redundant features and then eliminate irrelevant features in the second stage. One important advantage of our algorithm is its generality, which means the method works for correlated feature spaces without preprocessing. It can be implemented along with any single-pass online classification method with separating hyperplane such as SVMs. The proposed method is primarily developed for online tasks, however, we achieve very significant experimental results in comparison with popular batch feature ranking/selection methods. We also perform experiments to compare the method with available online feature ranking methods. Empirical results suggest that our method can be successfully implemented in batch learning or online mode.},
annote = {Artigo que apresenta um m{\'{e}}todo de sele{\c{c}}{\~{a}}o de atributos em data streams.},
author = {Razmjoo, Alaleh and Xanthopoulos, Petros and Zheng, Qipeng Phil},
doi = {10.1016/j.eswa.2017.05.016},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Razmjoo, Xanthopoulos, Zheng - 2017 - Online feature importance ranking based on sensitivity analysis(2).pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
pages = {397--406},
title = {{Online feature importance ranking based on sensitivity analysis}},
volume = {85},
year = {2017}
}

@inproceedings{Chen2011,
annote = {Artigo que apresenta uma t{\'{e}}cnica de redu{\c{c}}{\~{a}}o de dados conhecida como Online Fractal Dimensionality Reduction aplicada {\`{a}} streams. Cont{\'{e}}m datasets interessantes e que podem ser utilizados.},
author = {Chen, Zhizhong and He, Ruichun and Li, Yinzhen},
booktitle = {2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)},
doi = {10.1109/FSKD.2011.6019844},
isbn = {978-1-61284-180-9},
month = {jul},
pages = {1480--1484},
publisher = {IEEE},
address = {Shanghai, China},
title = {{Online fractal dimensionality reduction in time decaying stream environment}},
year = {2011}
}

@inproceedings{Rajput2014,
author = {Rajput, Rahul and Mishra, Aishwarya and Kumar, Sandeep},
booktitle = {2014 Fourth International Conference on Communication Systems and Network Technologies},
doi = {10.1109/CSNT.2014.87},
isbn = {978-1-4799-3070-8},
mendeley-groups = {IEEE Potenciais (Titulo),An{\'{a}}lise completa},
month = {apr},
pages = {408--413},
publisher = {IEEE},
address = {Bhopal, India},
title = {{Optimize Intrusion Prevention and Minimization of Threats for Stream Data Classification}},
year = {2014}
}

@inproceedings{Hosseini2011,
author = {Hosseini, Mohammad Javad and Ahmadi, Zahra and Beigy, Hamid},
booktitle = {2011 IEEE 11th International Conference on Data Mining Workshops},
doi = {10.1109/ICDMW.2011.137},
isbn = {978-1-4673-0005-6},
month = {dec},
pages = {588--595},
publisher = {IEEE},
address = {Vancouver, Canada},
title = {{Pool and Accuracy Based Stream Classification: A New Ensemble Algorithm on Data Stream Classification Using Recurring Concepts Detection}},
year = {2011}
}

@article{MiguelAngel2016,
abstract = {Stream-mining approach is defined as a set of cutting-edge techniques designed to process streams of data in real time, in order to extract knowledge. In the particular case of classification, stream-mining has to adapt its behavior to the volatile underlying data distributions, what has been called concept drift. It is important to note that concept drift may lead to situations where predictive models become invalid and have therefore to be updated to represent the actual concepts that data poses. In this context, there is a specific type of concept drift, known as recurrent concept drift, where the concepts represented by data have already appeared in the past. In those cases the learning process could be saved or at least minimized by applying a previously trained model. To deal with the aforementioned scenario, meta-models can be used in the process of enhancing the drift detection mechanisms used by data stream algorithms, by representing and predicting when the change will occur. There are some real-world situations where a concept reappears, as in the case of intrusion detection systems (IDS), where the same incidents or an adaptation of them usually reappear over time. In these environments the early prediction of drift by means of a better knowledge of past models can help to anticipate to the change, thus improving efficiency of the model regarding the training instances needed. Furthermore, as a complement of meta-models, a mechanism to assess the similarity between classification models is also needed when dealing with recurrent concepts. In this context, when reusing a previously trained model a rough comparison between concepts is usually made, applying boolean logic. The introduction of fuzzy logic comparisons between models could lead to a better efficient reuse of previously seen concepts, by applying not just equal models, but also similar ones. This work faces the aforementioned open issues by means of the MM-PRec system, that integrates a meta-model mechanism and a fuzzy similarity function. The theoretical proposal of MM-PRec is also validated in this paper by means of different experiments using both synthetic and real datasets.},
annote = {Artigo que discorre sobre o concept drift recorrente e os meios poss{\'{i}}veis de se prever a ocorr{\^{e}}ncia dos mesmos. {\'{U}}til para refer{\^{e}}ncias sobre esse tipo de concept drift.},
author = {Miguel Ángel Abad and João Bártolo Gomes and Ernestina
Menasalvas},
doi = {10.1016/j.eswa.2015.10.022},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Miguel {\'{A}}ngel, Jo{\~{a}}o B{\'{a}}rtolo, Ernestina - 2016 - Predicting recurring concepts on data-streams by means of a meta-model and a fuzzy sim(2).pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
pages = {87--105},
title = {{Predicting recurring concepts on data-streams by means of a meta-model and a fuzzy similarity function}},
volume = {46},
year = {2016}
}
@article{GoncalvesJr2013,
abstract = {This paper presents recurring concept drifts (RCD), a framework that offers an alternative approach to handle data streams that suffer from recurring concept drifts (on-line learning). It creates a new classifier to each context found and stores a sample of data used to build it. When a new concept drift occurs, the algorithm compares the new context to previous ones using a non-parametric multivariate statistical test to verify if both contexts come from the same distribution. If so, the corresponding classifier is reused. The RCD framework is compared with several algorithms (among single and ensemble approaches), in both artificial and real data sets, chosen from frequently used algorithms and data sets in the concept drift research area. We claim the proposed framework had better average ranks in data sets with abrupt and gradual concept drifts compared to both the single classifiers and the ensemble approaches that use the same base learner.},
annote = {Artigo que apresenta um framework para lidar com concept drifts recorrentes. O mesmo foi testado em datasets reais e artificiais que podem ser utilizados neste trabalho.},
author = {{GON\c{C}ALVES JR.}, Paulo Mauricio and de Barros, Roberto Souto Maior},
journal = {Pattern Recognition Letters},
doi = {10.1016/j.patrec.2013.02.005},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gon{\c{c}}alves Jr, Barros - 2013 - RCD A recurring concept drift framework(2).pdf:pdf},
issn = {01678655},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
number = {9},
pages = {1018--1025},
title = {{RCD: A recurring concept drift framework}},
volume = {34},
year = {2013}
}
@article{Barros2017,
abstract = {Concept drift detectors are online learning software that mostly attempt to estimate the drift positions in data streams in order to modify the base classifier after these changes and improve accuracy. This is very important in applications such as the detection of anomalies in TCP/IP traffic and/or frauds in financial transactions. Drift Detection Method (DDM) is a simple, efficient, well-known method whose performance is often impaired when the concepts are very long. This article proposes the Reactive Drift Detection Method (RDDM), which is based on DDM and, among other modifications, discards older instances of very long concepts aiming to detect drifts earlier, improving the final accuracy. Experiments run in MOA, using abrupt and gradual concept drift versions of different dataset generators and sizes (48 artificial datasets in total), as well as three real-world datasets, suggest RDDM beats the accuracy results of DDM, ECDD, and STEPD in most scenarios.},
annote = {Artigo que apresenta um detector de drift testado em diferentes datasets reais e artificiais com diferentes tipos de concept drift que podem ser utilizados neste trabalho.},
author = {Barros, Roberto S.M. and Cabral, Danilo R.L. and Gonc̨ alves, Paulo M. and Santos, Silas G.T.C.},
doi = {10.1016/j.eswa.2017.08.023},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Barros et al. - 2017 - RDDM Reactive Drift Detection Method(2).pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
title = {{RDDM: Reactive Drift Detection Method}},
year = {2017}
}
@article{Bolon-Canedo2015,
abstract = {In an era of growing data complexity and volume and the advent of big data, feature selection has a key role to play in helping reduce high-dimensionality in machine learning problems. We discuss the origins and importance of feature selection and outline recent contributions in a range of applications, from DNA microarray analysis to face recognition. Recent years have witnessed the creation of vast datasets and it seems clear that these will only continue to grow in size and number. This new big data scenario offers both opportunities and challenges to feature selection researchers, as there is a growing need for scalable yet efficient feature selection methods, given that existing methods are likely to prove inadequate.},
annote = {Artigo que apresenta os avan{\c{c}}os e os desafios da {\'{a}}rea de sele{\c{c}}{\~{a}}o de atributos no contexto de Big Data, incluindo estudos e algoritmos existentes em data streams.},
author = {Bol{\'{o}}n-Canedo, V. and S{\'{a}}nchez-Maro{\~{n}}o, N. and Alonso-Betanzos, A.},
doi = {10.1016/j.knosys.2015.05.014},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bol{\'{o}}n-Canedo, S{\'{a}}nchez-Maro{\~{n}}o, Alonso-Betanzos - 2015 - Recent advances and emerging challenges of feature selection in the context of(2).pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
pages = {33--45},
title = {{Recent advances and emerging challenges of feature selection in the context of big data}},
volume = {86},
year = {2015}
}
@inproceedings{Zhou2005,
address = {New York, New York, USA},
annote = {Artigo que apresenta um aprimoramento do algoritmo Streaming Feature Selection (SFS) e pode trazer novas ideias para o trabalho.},
author = {Zhou, Jing and Foster, Dean and Stine, Robert and Ungar, Lyle},
booktitle = {Proceeding of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining -- KDD '05},
doi = {10.1145/1081870.1081914},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2005 - Streaming feature selection using alpha-investing(2).pdf:pdf},
isbn = {159593135X},
mendeley-groups = {Adsense/ACM Potenciais (Titulo),An{\'{a}}lise completa},
pages = {384},
publisher = {ACM Press},
title = {{Streaming feature selection using alpha-investing}},
year = {2005}
}
@article{Zhang2017,
abstract = {Text data streams have widely appeared in real-world applications, in which, concept drifts owe a significant challenge for classification. Compared with relational data streams, concept drifts hidden in text streams usually reflect in the relationship between the feature vector and the instance labels. Meanwhile, existing concept drifting detection methods are mainly based on error rates of classification. When applying these methods in text streams, they perform poorly in the evaluations of false alarms and missing detections, etc. Motivated by this, we firstly give a systematic analysis of the concept drifts in text data streams. Then, we propose a three-layer concept drifting detection approach, where the three layers indicate the layer of label space, the layer of feature space and the layer of the mapping relationships between labels and features, respectively. In this approach, the latter two layers are based on the values of WoE (Weight of Evidence) and the IV (Information Value) index. Experimental results show that our approach can improve the performance of concept drifting detection and the accuracy of classification, especially when concept drifts in text data streams are frequent.},
annote = {Estudo que apresenta, dentre outros aspectos, os tipos de concept drift que podem acontecer no campo de minera{\c{c}}{\~{a}}o de texto em data streams.},
author = {Zhang, Yuhong and Chu, Guang and Li, Peipei and Hu, Xuegang and Wu, Xindong},
doi = {10.1016/j.neucom.2017.04.047},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - Three-layer concept drifting detection in text data streams(2).pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
mendeley-groups = {Science Direct Potenciais (Titulo),An{\'{a}}lise completa},
pages = {393--403},
title = {{Three-layer concept drifting detection in text data streams}},
volume = {260},
year = {2017}
}
@inproceedings{Huang2015,
address = {New York, New York, USA},
annote = {Artigo que apresenta um algoritmo de sele{\c{c}}{\~{a}}o de atributos n{\~{a}}o supervisionado em data streams, que funciona inclusive na presen{\c{c}}a de concept drifts.},
author = {Huang, Hao and Yoo, Shinjae and Kasiviswanathan, Shiva Prasad},
booktitle = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management - CIKM '15},
doi = {10.1145/2806416.2806521},
isbn = {9781450337946},
mendeley-groups = {Adsense/ACM Potenciais (Titulo),An{\'{a}}lise completa},
pages = {1031--1040},
publisher = {ACM Press},
title = {{Unsupervised Feature Selection on Data Streams}},
year = {2015}
}

@book{Han2006,
author = {Han, Jiawei and Kamber, Micheline},
publisher = {Elsevier},
pages = {743},
title = {{Data Mining Concepts and Techniques}},
volume = {2},
address = {Burlington},
year = {2006}
}

@article{Dobre2014,
abstract = {Cities are areas where Big Data is having a real impact. Town planners and administration bodies just need the right tools at their fingertips to consume all the data points that a town or city generates and then be able to turn that into actions that improve peoples' lives. In this case, Big Data is definitely a phenomenon that has a direct impact on the quality of life for those of us that choose to live in a town or city. Smart Cities of tomorrow will rely not only on sensors within the city infrastructure, but also on a large number of devices that will willingly sense and integrate their data into technological platforms used for introspection into the habits and situations of individuals and city-large communities. Predictions say that cities will generate over 4.1 terabytes per day per square kilometer of urbanized land area by 2016. Handling efficiently such amounts of data is already a challenge. In this paper we present our solutions designed to support next-generation Big Data applications. We first present CAPIM, a platform designed to automate the process of collecting and aggregating context information on a large scale. It integrates services designed to collect context data (location, user's profile and characteristics, as well as the environment). Later on, we present a concrete implementation of an Intelligent Transportation System designed on top of CAPIM. The application is designed to assist users and city officials better understand traffic problems in large cities. Finally, we present a solution to handle efficient storage of context data on a large scale. The combination of these services provides support for intelligent Smart City applications, for actively and autonomously adaptation and smart provision of services and content, using the advantages of contextual information. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {Dobre, C. and Xhafa, F.},
doi = {10.1016/j.future.2013.07.014},
file = {:C$\backslash$:/Users/Bernardelli/Google Drive/Mestrado/Disserta{\c{c}}{\~{a}}o/Artigos/1-s2.0-S0167739X13001593-main.pdf:pdf},
journal = {Future Generation Computer Systems},
keywords = {Big Data,Context,Context-aware services,Intelligent Transport Systems,Intelligent services,Mobile computing,Smart City applications},
mendeley-groups = {Ferramentas Estatisticas},
pages = {267--281},
publisher = {Elsevier B.V.},
title = {{Intelligent services for Big data science}},
volume = {37},
year = {2014}
}

@article{Gradvohl2016,
abstract = {Despite companies' demand for data streams pro cessing systems to handle large volumes of flowing data, we did not find many software to assess these sort of systems. In fact, up to date, there are few papers proposing metrics to evaluate these systems or describing software for benchmarks. Most of the papers focus on metrics such as throughput, latency and memory consumption. However, there are other metrics, which system administrators and users should consider, such as information latency, the correctness of results, adaptability on different workloads and others. Therefore, in this paper, we summarized some key metrics used to assess systems for processing online data streams. In addition, we discuss three benchmark tools found in the literature to assess this type of system. At the end of this paper, we propose a new benchmark tool for complex event processing distributed systems called B2- 4CEP, which incorporate the metrics described in this paper.},
author = {Gradvohl, Andre Leon S.},
doi = {10.1109/W-FiCloud.2016.40},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gradvohl - 2016 - Investigating metrics to build a benchmark tool for complex event processing systems.pdf:pdf},
isbn = {9781509039463},
journal = {Proceedings - 2016 4th International Conference on Future Internet of Things and Cloud Workshops, W-FiCloud 2016},
keywords = {Benchmark,Complex event processing,Metrics},
mendeley-groups = {Data Streams and Complext Event Processing},
pages = {143--147},
title = {{Investigating metrics to build a benchmark tool for complex event processing systems}},
year = {2016}
}
@article{Gradvohl2014,
abstract = {This paper presents an analysis of four online stream processing systems (MillWheel, S4, Spark Streaming and Storm) regarding the strategies they use for fault tolerance. We use this sort of system for processing of data streams that can come from different sources such as web sites, sensors, mobile phones or any set of devices that provide real-time high-speed data. Typically, these systems are concerned more with the throughput in data processing than on fault tolerance. However, depending on the type of application, we should consider fault tolerance as an important a feature. The work describes some of the main strategies for fault tolerance {\&}ndash; replication components, upstream backup, checkpoint and recovery {\&}ndash; and shows how each of the four systems uses these strategies. In the end, the paper discusses the advantages and disadvantages of the combination of the strategies for fault tolerance in these systems.},
author = {Gradvohl, Andr{\'{e}} Leon Sampaio and Senger, Hermes and Arantes, Luciana and Sens, Pierre},
doi = {10.4304/jetwi.6.2.174-179},
issn = {17998859},
journal = {Journal of Emerging Technologies in Web Intelligence},
keywords = {Distributed systems,Fault-tolerance,Online stream processing.,Systemapplications},
mendeley-groups = {Data Streams and Complext Event Processing},
number = {2},
pages = {174--179},
title = {{Comparing distributed online stream processing systems considering fault tolerance issues}},
volume = {6},
year = {2014}
}

@article{Gama2010,
abstract = {In the last two decades, machine learning research and practice has fo- cused on batch learning, usually with small datasets. Nowadays there are appli- cations in which the data are modeled best not as persistent tables, but rather as transient data streams. Learning from data streams is an increasing research area with challenging applications and contributions from fields like data bases, learn- ing theory, machine learning, and data mining. In this work we identify the main characteristics of stream mining algorithms, and present two illustrative examples of such algorithms.},
author = {Gama, Jo{\~{a}}o and Rodrigues, Pedro Pereira and Spinosa, Eduardo and Carvalho, Andre},
doi = {10.3233/978-1-60750-611-9-125},
file = {:C$\backslash$:/Users/Matheus/Google Drive/Mestrado/Disserta{\c{c}}{\~{a}}o/An{\'{a}}lise Completa/DataStreamsCRC.pdf:pdf},
isbn = {978-1-60750-610-2},
issn = {1088-467X},
journal = {Web Intelligence and Security - Advances in Data and Text Mining Techniques for Detecting and Preventing Terrorist Activities on the Web},
keywords = {clustering,data mining,data streams},
mendeley-groups = {Data Streams and Complext Event Processing},
pages = {125--138},
pmid = {21894043},
title = {{Knowledge Discovery from Data Streams}},
year = {2010}
}

@article{Krempl2014,
abstract = {Every day, huge volumes of sensory, transactional, and web data are continuously generated as streams, which need to be analyzed online as they arrive. Streaming data can be considered as one of the main sources of what is called big data. While predictive modeling for data streams and big data have received a lot of at-tention over the last decade, many research approaches are typi-cally designed for well-behaved controlled problem settings, over-looking important challenges imposed by real-world applications. This article presents a discussion on eight open challenges for data stream mining. Our goal is to identify gaps between current re-search and meaningful applications, highlight open problems, and define new application-relevant research directions for data stream mining. The identified challenges cover the full cycle of knowledge discovery and involve such problems as: protecting data privacy, dealing with legacy systems, handling incomplete and delayed in-formation, analysis of complex data, and evaluation of stream min-ing algorithms. The resulting analysis is illustrated by practical applications and provides general suggestions concerning lines of future research in data stream mining.},
author = {Krempl, Georg and Spiliopoulou, Myra and Stefanowski, Jerzy and {\v{Z}}liobaite, Indre and Brzezi{\'{n}}ski, Dariusz and H{\"{u}}llermeier, Eyke and Last, Mark and Lemaire, Vincent and Noack, Tino and Shaker, Ammar and Sievi, Sonja},
doi = {10.1145/2674026.2674028},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Krempl et al. - 2014 - Open challenges for data stream mining research.pdf:pdf},
isbn = {1931-0145},
issn = {19310145},
journal = {ACM SIGKDD Explorations Newsletter},
mendeley-groups = {Data Streams and Complext Event Processing},
number = {1},
pages = {1--10},
title = {{Open challenges for data stream mining research}},
volume = {16},
year = {2014}
}

@article{Guyon2003,
abstract = {Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the pre- dictors, providing faster andmore cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Guyon, Isabelle and Elisseeff, Andr{\'{e}}},
doi = {10.1016/j.aca.2011.07.027},
eprint = {1111.6189v1},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Guyon, Elisseeff - 2003 - An Introduction to Variable and Feature Selection.pdf:pdf},
isbn = {0885-6125},
issn = {00032670},
journal = {Journal of Machine Learning Research (JMLR)},
keywords = {Biochemical oxygen demand,Kernel discriminant analysis,Kernel partial least squares,Support vector classification,Support vector regression,Water quality},
mendeley-groups = {Feature selection},
number = {3},
pages = {1157--1182},
pmid = {21889629},
title = {{An Introduction to Variable and Feature Selection}},
volume = {3},
year = {2003}
}


@article{Donoho2000,
abstract = {The coming century is surely the century of data. A combination of blind faith and serious purpose makes our society invest massively in the collection and processing of data of all kinds, on scales unimaginable until recently. Hyperspectral Imagery, Internet Portals, Financial tick-by-tick data, and DNA Microarrays are just a few of the better-known sources, feeding data in torrential streams into scientific and business databases worldwide. In traditional statistical data analysis, we think of observations of instances of par-ticular phenomena (e.g. instance ↔ human being), these observations being a vector of values we measured on several variables (e.g. blood pressure, weight, height, ...). In traditional statistical methodology, we assumed many observations and a few, well-chosen variables. The trend today is towards more observations but even more so, to radically larger numbers of variables – voracious, automatic, systematic collection of hyper-informative detail about each observed instance. We are seeing examples where the observations gathered on individual instances are curves, or spectra, or images, or even movies, so that a single observation has dimensions in the thousands or billions, while there are only tens or hundreds of instances available for study. Classical methods are simply not designed to cope with this kind of explosive growth of dimensionality of the observation vector. We can say with complete confidence that in the coming cen-tury, high-dimensional data analysis will be a very significant activity, and completely new methods of high-dimensional data analysis will be developed; we just don't know what they are yet. Mathematicians are ideally prepared for appreciating the abstract issues involved in finding patterns in such high-dimensional data. Two of the most influential prin-ciples in the coming century will be principles originally discovered and cultivated by mathematicians: the blessings of dimensionality and the curse of dimensionality. The curse of dimensionality is a phrase used by several subfields in the mathematical sciences; I use it here to refer to the apparent intractability of systematically searching through a high-dimensional space, the apparent intractability of accurately approxi-mating a general high-dimensional function, the apparent intractability of integrating a high-dimensional function. The blessings of dimensionality are less widely noted, but they include the concen-tration of measure phenomenon (so-called in the geometry of Banach spaces), which means that certain random fluctuations are very well controlled in high dimensions and the success of asymptotic methods, used widely in mathematical statistics and statis-tical physics, which suggest that statements about very high-dimensional settings may be made where moderate dimensions would be too complicated. 1 There is a large body of interesting work going on in the mathematical sciences, both to attack the curse of dimensionality in specific ways, and to extend the benefits of dimensionality. I will mention work in high-dimensional approximation theory, in probability theory, and in mathematical statistics. I expect to see in the coming decades many further mathematical elaborations to our inventory of Blessings and Curses, and I expect such contributions to have a broad impact on society's ability to extract meaning from the massive datasets it has decided to compile. At the end of my talk, I will also draw on my personal research experiences. This suggest to me (1) ongoing developments in high-dimensional data analysis may lead mathematicians to study new problems in for example harmonic analysis; and (2) that many of the problems of low dimensional data analysis are unsolved and are similar to problems in harmonic analysis which have only recently been attacked, and for which only the merest beginnings have been made. Both fields can progress together. Dedication. To the Memory of John Wilder Tukey 1915-2000.},
author = {Donoho, David L},
doi = {10.1.1.329.3392},
file = {:C$\backslash$:/Users/Matheus/Google Drive/Mestrado/Disserta{\c{c}}{\~{a}}o/An{\'{a}}lise Completa/8278418b69f60b4814fae8dd15b1b1854295.pdf:pdf},
journal = {American Math. Society Lecture-Math Challenges of the 21st Century},
keywords = {Acknowledgments,Algorithms,Analy-sis,Analysis,Components,Computational,Data,Harmonic,Independent,Mining,Multivariate,Principal,Randomized,The effort to prepare},
mendeley-groups = {Feature selection},
pages = {1--33},
title = {{Aide-Memoire. High-Dimensional Data Analysis: The Curses and Blessings of Dimensionality}},
year = {2000}
}

@article{Tan2014,
abstract = {In this paper, we present a new adaptive feature scaling scheme for ultrahigh-dimensional feature selection on Big Data, and then reformulate it as a convex semi-infinite programming (SIP) problem. To address the SIP, we propose an eficient feature generating paradigm. Different from traditional gradient-based approaches that conduct optimization on all input features, the proposed paradigm iteratively activates a group of features, and solves a sequence of multiple kernel learning (MKL) subproblems. To further speed up the training, we propose to solve the MKL subproblems in their primal forms through a modified accelerated proximal gradient approach. Due to such optimization scheme, some eficient cache techniques are also developed. The feature generating paradigm is guaranteed to converge globally under mild conditions, and can achieve lower feature selection bias. Moreover, the proposed method can tackle two challenging tasks in feature selection: 1) group-based feature selection with complex structures, and 2) nonlinear feature selection with explicit feature mappings. Comprehensive experiments on a wide range of synthetic and real-world data sets of tens of million data points with O(1014) features demonstrate the competitive performance of the proposed method over state-of-the-art feature selection methods in terms of generalization performance and training eficiency. {\textcopyright} 2014 Mingkui Tan, Ivor W. Tsang and Li Wang.},
author = {Tan, Mingkui and Tsang, Ivor W. and Wang, Li},
file = {:C$\backslash$:/Users/Matheus/Google Drive/Mestrado/Disserta{\c{c}}{\~{a}}o/An{\'{a}}lise Completa/tan14a.pdf:pdf},
isbn = {1532-4435},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Big data,Feature generation,Feature selection,Multiple kernel learning,Nonlinear feature selection,Ultrahigh dimensionality},
mendeley-groups = {Feature selection},
pages = {1371--1429},
title = {{Towards ultrahigh dimensional feature selection for big data}},
volume = {15},
year = {2014}
}

@article{Weinberger2009,
abstract = {Empirical evidence suggests that hashing is an effective strategy for dimensionality reduction and practical nonparametric estimation. In this paper we provide exponential tail bounds for feature hashing and show that the interaction between random subspaces is negligible with high probability. We demonstrate the feasibility of this approach with experimental results for a new use case -- multitask learning with hundreds of thousands of tasks.},
archivePrefix = {arXiv},
arxivId = {0902.2206},
author = {Weinberger, Kilian and Dasgupta, Anirban and Attenberg, Josh and Langford, John and Smola, Alex},
doi = {10.1145/1553374.1553516},
eprint = {0902.2206},
file = {:C$\backslash$:/Users/Matheus/Google Drive/Mestrado/Disserta{\c{c}}{\~{a}}o/An{\'{a}}lise Completa/Weinbergeretal09.pdf:pdf},
isbn = {9781605585161},
issn = {1605585165},
mendeley-groups = {Feature selection},
title = {{Feature Hashing for Large Scale Multitask Learning}},
year = {2009}
}

@article{Luckham2008,
author = {Luckham, Editors David and Schulte, Roy},
file = {:C$\backslash$:/Users/Matheus/Google Drive/Mestrado/Disserta{\c{c}}{\~{a}}o/An{\'{a}}lise Completa/epts-glossary-v11.pdf:pdf},
journal = {Event Processing Technical Society},
mendeley-groups = {Data Streams and Complext Event Processing},
number = {July},
pages = {1--19},
title = {{Event Processing Glossary - Version 1 . 1}},
year = {2008}
}

@inproceedings{Nguyen2012,
abstract = {The nature of data streams requires classification algorithms to be real-time, efficient, and able to cope with high-dimensional data that are continuously arriving. It is a known fact that in high-dimensional datasets, not all features are critical for training a classifier. To improve the performance of data stream classification, we propose an algorithm called HEFT-Stream (Heterogeneous Ensemble with Feature drifT for Data Streams) that incorporates feature selection into a heterogeneous ensemble to adapt to different types of concept drifts. As an example of the proposed framework, we first modify the FCBF [13] algorithm so that it dynamically update the relevant feature subsets for data streams. Next, a heterogeneous ensemble is constructed based on different online classifiers, including Online Naive Bayes and CVFDT [5]. Empirical results show that our ensemble classifier outperforms state-of-the-art ensemble classifiers (AWE [15] and OnlineBagging [21]) in terms of accuracy, speed, and scalability. The success of HEFT-Stream opens new research directions in understanding the relationship between feature selection techniques and ensemble learning to achieve better classification performance. {\textcopyright} 2012 Springer-Verlag.},
author = {Nguyen, Hai Long and Woon, Yew Kwong and Ng, Wee Keong and Wan, Li},
booktitle = {Advances in Knowledge Discovery and Data Mining},
doi = {10.1007/978-3-642-30220-6_1},
isbn = {9783642302190},
issn = {03029743},
mendeley-groups = {Concept drift},
number = {PART 2},
pages = {1--12},
publisher = {SpringerLink},
address = {Kuala Lumpur, Malaysia},
title = {{Heterogeneous ensemble for feature drifts in data streams}},
volume = {7301 LNAI},
year = {2012}
}

@article{Higashino2016,
abstract = {The emergence of Big Data has had profound impacts on how data are stored and processed. As technologies created to process continuous streams of data with low latency, Complex Event Processing (CEP) and Stream Processing (SP) have often been related to the Big Data velocity dimension and used in this context. Many modern CEP and SP systems leverage cloud environments to provide the low latency and scalability required by Big Data applications, yet validating these systems at the required scale is a research problem per se. Cloud computing simulators have been used as a tool to facilitate reproducible and repeatable experiments in clouds. Nevertheless, existing simulators are mostly based on simple application and simulation models that are not appropriate for CEP or for SP. This article presents CEPSim, a simulator for CEP and SP systems in cloud environments. CEPSim proposes a query model based on Directed Acyclic Graphs (DAGs) and introduces a simulation algorithm based on a novel abstraction called event sets. CEPSim is highly customizable and can be used to analyse the performance and scalability of user-defined queries and to evaluate the effects of various query processing strategies. Experimental results show that CEPSim can simulate existing systems in large Big Data scenarios with accuracy and precision.},
author = {Higashino, Wilson A. and Capretz, Miriam A.M. and Bittencourt, Luiz F.},
doi = {10.1016/j.future.2015.10.023},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Higashino, Capretz, Bittencourt - 2016 - CEPSim Modelling and simulation of Complex Event Processing systems in cloud environments.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Big Data,Cloud computing,Complex event processing,Simulation,Stream processing},
mendeley-groups = {Data Streams and Complext Event Processing},
pages = {122--139},
publisher = {Elsevier B.V.},
title = {{CEPSim: Modelling and simulation of Complex Event Processing systems in cloud environments}},
volume = {65},
year = {2016}
}

@article{Margara2011,
abstract = {An increasing number of distributed applications requires processing continuously flowing data from geographically distributed sources at unpredictable rate to obtain timely responses to complex queries. Examples of such applications come from the most disparate fields: from wireless sensor networks to financial tickers, from traffic management to click stream inspection. These requirements led to the development of a number of systems specifically designed to process information as a flow according to a set of pre-deployed processing rules. We collectively call them Information Flow Processing (IFP) Systems. Despite having a common goal, IFP systems differ in a wide range of aspects, including architectures, data models, rule languages, and processing mechanisms. In this tutorial we draw a general framework to analyze and compare the results achieved so far in the area of IFP systems. This allows us to offer a systematic overview of the topic, favoring the communication between different communities, and highlighting a number of open issue that still need to be addressed in research. {\&}copy; 2011 Authors.},
author = {Margara, Alessandro and Cugola, Gianpaolo},
doi = {10.1145/2002259.2002307},
file = {:C$\backslash$:/Users/Matheus/Google Drive/Mestrado/Disserta{\c{c}}{\~{a}}o/An{\'{a}}lise Completa/cep{\_}survey.pdf:pdf},
isbn = {9781450309059},
journal = {DEBS'11 - Proceedings of the 5th ACM International Conference on Distributed Event-Based Systems},
keywords = {Software architecture;Wireless sensor networks;},
mendeley-groups = {Data Streams and Complext Event Processing},
number = {i},
pages = {359--360},
title = {{Processing flows of information: From data stream to complex event processing}},
volume = {V},
year = {2011}
}

@article{Luckham1997,
author = {Luckham, David C},
file = {:C$\backslash$:/Users/Matheus/Google Drive/Mestrado/Disserta{\c{c}}{\~{a}}o/An{\'{a}}lise Completa/CSL-TR-96-705.pdf:pdf},
isbn = {0-8218-0579-7},
journal = {POMIV '96: Proceedings of the DIMACS workshop on Partial order methods in verification},
mendeley-groups = {Data Streams and Complext Event Processing},
pages = {329--357},
title = {{Rapide: a language and toolset for simulation of distributed systems by partial orderings of events}},
year = {1997}
}

@article{Arasu2004,
abstract = {A good overview of the Stanford Data Stream Management System project as of March 2004.},
author = {Arasu, Arvind and Babcock, Brian and Babu, Shivnath and Cieslewicz, John and Ito, Keith and Motwani, Rajeev and Srivastava, Utkarsh and Widom, Jennifer},
doi = {http://ilpubs.stanford.edu:8090/641/1/2004-20.pdf},
file = {:C$\backslash$:/Users/Matheus/Google Drive/Mestrado/Disserta{\c{c}}{\~{a}}o/An{\'{a}}lise Completa/2004-20.pdf:pdf},
isbn = {158113634X},
issn = {2153-5418},
journal = {Concrete},
mendeley-groups = {Data Streams and Complext Event Processing},
number = {2004-20},
pages = {1--21},
title = {{STREAM: The Stanford Data Stream Management System}},
year = {2004}
}
@article{Carney2003,
abstract = {Abstract.This paper describes the basic processing model and architecture of Aurora, a new system to manage data streams for monitoring applications. Monitoring applications differ substantially from conventional business data processing. The fact that ...},
author = {Carney, Don and Cetintemel, Ugur and Tatbul, Nesime and Stonebraker, Michael and Abadi, Daniel J. and Zdonik, Stan and Convey, Christian and Lee, Sangdon and Cherniack, Mitch},
doi = {10.1007/s00778-003-0095-z},
file = {:C$\backslash$:/Users/Matheus/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Carney et al. - 2003 - Aurora A New Model and Architecture for Data Stream Management.pdf:pdf},
isbn = {3555304623},
issn = {10668888},
journal = {Proceedings of the the VLDB Endowment},
keywords = {continuous queries,data stream management,database triggers,quality-of-service,real-time systems},
mendeley-groups = {Data Streams and Complext Event Processing},
number = {2},
pages = {120--139},
pmid = {5956130271908022888},
title = {{Aurora: A New Model and Architecture for Data Stream Management}},
volume = {12},
year = {2003}
}


@incollection{Katakis2005,
  author      = "Katakis, Ioannis and Tsoumakas, Ioannis Vlahavas",
  title       = "On the Utility of Incremental Feature Selection for the Classification of Textual Data Streams",
  editor      = "Jan Fagerberg and David C. Mowery and Richard R. Nelson",
  booktitle   = "Advances in Informatics",
  publisher   = "SpringerLink",
  address     = "Volos,Greece",
  year        = 2005,
  pages       = "338-348",
}

@article{Wang2014,
abstract = {Feature selection is an important technique for data mining. Despite its importance, most studies of feature selection are restricted to batch learning. Unlike traditional batch learning methods, online learning represents a promising family of efficient and scalable machine learning algorithms for large-scale applications. Most existing studies of online learning require accessing all the attributes/features of training instances. Such a classical setting is not always appropriate for real-world applications when data instances are of high dimensionality or it is expensive to acquire the full set of attributes/features. To address this limitation, we investigate the problem of online feature selection (OFS) in which an online learner is only allowed to maintain a classifier involved only a small and fixed number of features. The key challenge of online feature selection is how to make accurate prediction for an instance using a small number of active features. This is in contrast to the classical setup of online learning where all the features can be used for prediction. We attempt to tackle this challenge by studying sparsity regularization and truncation techniques. Specifically, this article addresses two different tasks of online feature selection: 1) learning with full input, where an learner is allowed to access all the features to decide the subset of active features, and 2) learning with partial input, where only a limited number of features is allowed to be accessed for each instance by the learner. We present novel algorithms to solve each of the two problems and give their performance analysis. We evaluate the performance of the proposed algorithms for online feature selection on several public data sets, and demonstrate their applications to real-world problems including image classification in computer vision and microarray gene expression analysis in bioinformatics. The encouraging results of our experiments validate the efficacy and efficiency of th- proposed techniques.},
annote = {Online Feature Selection (OFS)},
author = {Wang, Jialei and Zhao, Peilin and Hoi, Steven C.H. and Jin, Rong},
doi = {10.1109/TKDE.2013.32},
file = {:home/athos/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2014 - Online feature selection and its applications.pdf:pdf},
isbn = {1041-4347},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Feature selection,big data analytics,classification,large-scale data mining,online learning},
mendeley-groups = {Feature selection,Feature selection/Algorithms},
number = {3},
pages = {698--710},
title = {{Online feature selection and its applications}},
volume = {26},
year = {2014}
}

@article{Carvalho2006,
abstract = {To learn concepts over massive data streams, it is essential to design inference and learning methods that operate in real time with limited memory. Online learning methods such as perceptron or Winnow are naturally suited to stream processing; however},
annote = {Extreme Feature Selection (EFS)},
author = {Carvalho, Vitor R. and Cohen, William W.},
doi = {10.1145/1150402.1150466},
file = {:home/athos/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carvalho, Cohen - 2006 - Single-pass online learning.pdf:pdf},
isbn = {1595933395},
journal = {Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining  - KDD '06},
keywords = {averaging,online learning,single-pass,voting,winnow},
mendeley-groups = {Feature selection/Algorithms},
pages = {548},
title = {{Single-pass online learning}},
year = {2006}
} %url = {http://portal.acm.org/citation.cfm?doid=1150402.1150466},

@article{Yu2003,
abstract = {Feature selection, as a preprocessing step to machine learning, is effective in reducing dimensionality, removing irrelevant data, increasing learning accuracy, and improving result comprehensibility. However, the recent increase of dimensionality of data poses a severe challenge to many existing feature selection methods with respect to efficiency and effectiveness. In this work, we introduce a novel concept, predominant correlation, and propose a fast filter method which can identify relevant features as well as redundancy among relevant features without pairwise correlation analysis. The efficiency and effectiveness of our method is demonstrated through extensive comparisons with other methods using real-world data of high dimensionality.},
annote = {Fast Correlation-Based Filter (FCBF)},
author = {Yu, Lei and Liu, Huan},
doi = {citeulike-article-id:3398512},
file = {:home/athos/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Liu - 2003 - Feature Selection for High-Dimensional Data A Fast Correlation-Based Filter Solution.pdf:pdf},
isbn = {1577351894},
issn = {01469592},
journal = {International Conference on Machine Learning (ICML)},
mendeley-groups = {Feature selection/Algorithms},
pages = {1--8},
title = {{Feature Selection for High-Dimensional Data: A Fast Correlation-Based Filter Solution}},

year = {2003}
}%url = {http://www.aaai.org/Papers/ICML/2003/ICML03-111.pdf},

@article{Quinlan1986,
abstract = {The technology for building knowledge-based systems by inductive inference from examples has been demonstrated successfully in several practical applications. This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail. Results from recent studies show ways in which the methodology can be modified to deal with information that is noisy and/or incomplete. A reported shortcoming of the basic algorithm is discussed and two means of overcoming it are compared. The paper concludes with illustrations of current research directions.},
author = {Quinlan, J. R.},
doi = {10.1023/A:1022643204877},
file = {:home/athos/Downloads/BF00116251.pdf:pdf},
isbn = {0885-6125},
issn = {15730565},
journal = {Machine Learning},
keywords = {classification,decision trees,expert systems,induction,information theory,knowledge acquisition},
mendeley-groups = {Feature selection/Algorithms},
number = {1},
pages = {81--106},
pmid = {17050186},
title = {{Induction of Decision Trees}},
volume = {1},
year = {1986}
}

@article{Wang2015,
annote = {Online Feature Group Selection (OFGS)},
author = {Wang, Jing and Wang, Meng and Li, Peipei and Liu, Luoqi and Zhao, Zhongqiu and Hu, Xuegang and Wu, Xindong},
file = {:home/athos/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2015 - Online Feature Selection with Group Structure Analysis.pdf:pdf},
mendeley-groups = {Feature selection/Algorithms},
number = {11},
pages = {3029--3041},
title = {{Online Feature Selection with Group Structure Analysis}},
volume = {27},
year = {2015}
}

@article{Wu2013,
annote = {Online Streaming Feature Selection (OSFS)},
author = {Wu, Xindong and Yu, Kui and Ding, Wei and Wang, Hao and Zhu, Xingquan and Member, Senior},
file = {:home/athos/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2013 - Online Feature Selection with Streaming Features.pdf:pdf},
mendeley-groups = {Feature selection/Algorithms},
number = {5},
pages = {1178--1192},
title = {{Online Feature Selection with Streaming Features}},
volume = {35},
year = {2013}
}

@misc{March1991,
abstract = {Este paper considera la relaci{\'{o}}n entre la exploraci{\'{o}}n de nuevas posibilidades y la explotaci{\'{o}}n de viejas verdades absolutas en aprendizaje organizacional. Examina algunas complicaciones en asignar recursos entre las dos, particularmente esos generados por la distribuci{\'{o}}n de costos y beneficios a trav{\'{e}}s del tiempo y del espacio, y los efectos de la interacci{\'{o}}n ecol{\'{o}}gica. Dos situaciones generales implicadas en el desarrollo y el uso del conocimiento se modelaron. La primera es el caso del aprendizaje mutuo entre los miembros de una organizaci{\'{o}}n y un c{\'{o}}digo organizacional. La segunda es el caso del aprendizaje y la ventaja competitiva en la competencia por la primac{\'{i}}a. EL paper argumenta que los procesos adaptativos, por refinar la explotaci{\'{o}}n m{\'{a}}s r{\'{a}}pido que la exploraci{\'{o}}n, son m{\'{a}}s efectivos en el corto plazo pero m{\'{a}}s autodestructivos en el largo plazo. Se eval{\'{u}}a la posibilidad de que algunas pr{\'{a}}cticas organizacionales mejoren esa tendencia.},
archivePrefix = {arXiv},
arxivId = {z0009},
author = {March, James G.},
booktitle = {Organization Science},
doi = {10.1287/orsc.2.1.71},
eprint = {z0009},
file = {:home/athos/Downloads/march.pdf:pdf},
isbn = {1047703915265},
issn = {1047-7039},
keywords = {Knowledge and Competitive Advantage,Organizational Learning,Risk Taking},
mendeley-groups = {Feature selection},
number = {1},
pages = {71--87},
pmid = {7601529},
title = {{Exploracion Y Explotacion En Aprendizaje Organizacional}},
volume = {2},
year = {1991}
}

@article{Valizadegan2011,
abstract = {We study multi-class bandit prediction, an online learning problem where the learner only receives a partial feedback in each trial indicating whether the predicted class label is correct. The exploration vs. exploitation tradeoff strategy is a well-known technique for online learning with incomplete feedback (i.e., bandit setup). Banditron [8], a multi-class online learning algorithm for bandit setting, maximizes the run-time gain by balancing between exploration and exploitation with a fixed tradeoff parameter. The performance of Banditron can be quite sensitive to the choice of the tradeoff parameter and therefore effective algorithms to automatically tune this parameter is desirable. In this paper, we propose three learning strategies to automatically adjust the tradeoff parameter for Banditron. Our extensive empirical study with multiple real-world data sets verifies the efficacy of the proposed approach in learning the exploration vs. exploitation tradeoff parameter.},
author = {Valizadegan, Hamed and Jin, Rong and Wang, Shijun},
doi = {10.1145/2020408.2020445},
file = {:home/athos/Downloads/885-Valizadegan.pdf:pdf},
isbn = {9781450308137},
issn = {1450308139},
journal = {Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '11},
keywords = {bandit feedback,exploitation,exploration vs,multi-class classifica-,online learning,tion},
mendeley-groups = {Feature selection},
pages = {204},
title = {{Learning to trade off between exploration and exploitation in multiclass bandit prediction}},
year = {2011}
} %url = {http://dl.acm.org/citation.cfm?doid=2020408.2020445},

@article{Bifet2010,
  author    = {Albert Bifet and
               Geoff Holmes and
               Richard Kirkby and
               Bernhard Pfahringer},
  title     = {{MOA:} Massive Online Analysis},
  journal   = {Journal of Machine Learning Research},
  volume    = {11},
  pages     = {1601--1604},
  year      = {2010},
  timestamp = {Fri, 01 Apr 2011 14:32:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/jmlr/BifetHKP10},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}% url       = {http://portal.acm.org/citation.cfm?id=1859903},

@misc{githubMbdemoraes,
  author = {Matheus B. de Moraes},
  title = {{Data Streams With Feature Selection}},
  year = {2018}, 
  note = "Disponível em: \url{https://github.com/mbdemoraes/data-streams-feature-selection/}. Último acesso em 11 de maio de 2018"
}
%note = "[Online; accessed 11-May-2018]"
%howpublished = "\url{https://github.com/mbdemoraes/data-streams-feature-selection/}",

@article{Bifet2011,
abstract = {Data mining is a part of a process called KDD-knowledge discovery in databases. This process consists basi- cally of steps that are performed before carrying out data mining, such as data selection, data cleaning, pre-processing, and data transformation. Association rule techniques are used for data mining if the goal is to detect relationships or as- sociations between specific values of categorical variables in large data sets. There may be thousands or millions of records that have to be read and to extract the rules for, but the question is what will happen if there is new data, or there is a need to modify or delete some or all the existing set of data during the process of data mining. In the past user would repeat the whole procedure, which is time-consuming in addition to its lack of efficiency. From this, the importance of dynamic data mining process appears and for this reason this problem is going to be the main topic of this paper. Therefore the purpose of this study is to find solution for dynamic data mining process that is able to take into considerations all updates (insert, update, and delete problems) into account.},
author = {Bifet, Albert and Kirkby, Richard},
doi = {10.1007/978-0-387-09823-4_39},
file = {:home/athos/Downloads/10.1.1.192.1957.pdf:pdf},
isbn = {978-0-387-09822-7},
issn = {21508097},
journal = {Methodology},
mendeley-groups = {Data Streams and Complext Event Processing},
number = {May},
pages = {127--141},
title = {{Data Stream Mining}},
volume = {8},
year = {2011}
}%url = {http://dspace.cusat.ac.in/jspui/handle/123456789/3616},

@article{Moher2010,
abstract = {Reliable suicide statistics are a prerequisite for suicide monitoring and prevention. The aim of this study was to assess the reliability of suicide statistics through a systematic review of the international literature. We searched for relevant publications in EMBASE, Ovid Medline, PubMed, PsycINFO and the Cochrane Library up to October 2010. In addition, we screened related studies and reference lists of identified studies. We included studies published in English, German, French, Spanish, Norwegian, Swedish and Danish that assessed the reliability of suicide statistics. We excluded case reports, editorials, letters, comments, abstracts and statistical analyses. All three authors independently screened the abstracts, and then the relevant full-text articles. Disagreements were resolved through consensus. The primary search yielded 127 potential studies, of which 31 studies met the inclusion criteria and were included in the final review. The included studies were published between 1963 and 2009. Twenty were from Europe, seven from North America, two from Asia and two from Oceania. The manner of death had been re-evaluated in 23 studies (40-3,993 cases), and there were six registry studies (195-17,412 cases) and two combined registry and re-evaluation studies. The study conclusions varied, from findings of fairly reliable to poor suicide statistics. Thirteen studies reported fairly reliable suicide statistics or under-reporting of 0-10{\%}. Of the 31 studies during the 46-year period, 52{\%} found more than 10{\%} under-reporting, and 39{\%} found more than 30{\%} under-reporting or poor suicide statistics. Eleven studies reassessed a nationwide representative sample, although these samples were limited to suicide within subgroups. Only two studies compared data from two countries. The main finding was that there is a lack of systematic assessment of the reliability of suicide statistics. Few studies have been done, and few countries have been covered. The findings support the general under-reporting of suicide. In particular, nationwide studies and comparisons between countries are lacking.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Moher, David and Liberati, Alessandro and Tetzlaff, Jennifer and Altman, Douglas G.},
doi = {10.1016/j.ijsu.2010.02.007},
eprint = {arXiv:1011.1669v3},
isbn = {1743-9191},
issn = {17439191},
journal = {International Journal of Surgery},
keywords = {Evaluating health interventions,Improving quality,Meta-analyses,Reporting guidelines,Systematic reviews},
mendeley-groups = {Others},
number = {5},
pages = {336--341},
pmid = {20171303},
title = {{Preferred reporting items for systematic reviews and meta-analyses: The PRISMA statement}},
volume = {8},
year = {2010}
}

@article{Demsar2006,
abstract = {While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams.},
author = {Dem{\v{s}}ar, Janez},
file = {::},
journal = {Journal of Machine Learning Research},
keywords = {Friedman test,Wilcoxon signed ranks test,comparative studies,multiple comparisons tests,statistical methods},
mendeley-groups = {Statistics},
pages = {1--30},
title = {{Statistical Comparisons of Classifiers over Multiple Data Sets}},
volume = {7},
year = {2006}
}




